---
title: "Bot Finder"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
```

```{r get_data, include=FALSE}
# Script to pull data from Adobe Analytics and compare to past data to see if
# an apparent bot has emerged

# Load libraries
library(tidyverse)
library(RSiteCatalyst)

# Load the theme
source("./scripts/themes_ref.R")

# Set the end date to be the most recent Saturday
end_date <- (Sys.Date() - as.POSIXlt(Sys.Date())$wday - 1) %>%
  as.character()
# end_date <- "2017-05-13"

# How many weeks should be included?
num_weeks <- 6

# Set the start date to be 6 weeks before the end date
start_date <- as.character(as.Date(end_date) - 7 * num_weeks + 1) 

trend_metrics = c("visits", "orders")

# Set the elements to be used to look for bots. These ALL need to have
# subrelations enabled.
check_elements = c("operatingsystem","browser", "domain", "geocountry")

# We can't just throw all of these elements into an API call, as, the longer the
# list, the more likely it is to bork. So, we're going to be a bit brute force and
# pull for _each_ element in the list, and then for each _pair_ of elements in the
# list.
elements_list <- c(as.list(check_elements),combn(check_elements, 2, simplify=FALSE))
# elements_list <- combn(check_elements, 2, simplify=FALSE)

# Get authentication credentials
adobe_key = Sys.getenv("ADOBE_API_USERNAME_MSC")
adobe_secret = Sys.getenv("ADOBE_API_SECRET_MSC")
rsid = Sys.getenv("ADOBE_RSID_MSC")

# Authenticate
SCAuth(adobe_key, adobe_secret)

# Vector of segment IDs to apply to data when pulling. The two below are
# `No Punchouts or Bots` and `Last Touch Channel = Direct` and `Exclude: Identified Bots`
segment_ids <- c("537ce3d0e4b083ab6f5eccbd","s300000270_58571c53e4b0374f4d0c19d0", "s300000270_595401b317a04517c5a37365")
# segment_ids <- ""

####################
# Main function to pull and process the data. The output of the function is a
# ggplot object
####################

look_for_bots <- function(trend_elements){

# Get the data
trended_data <- QueueTrended(rsid,
                           date.from = start_date,
                           date.to = end_date,
                           metrics = trend_metrics,
                           elements = trend_elements,
                           date.granularity = "week",
                           segment.id = segment_ids)

# Convert the datetime from POSIXlt to Date. Has it always come back as POSIXlt?
trended_data$datetime <- as.Date(trended_data$datetime)

# A little quirk here. IF there is only a single dimension being evaluated,
# then the name of the dimension column is "name." If multiple elements are
# being evaluated, then the dimension columns are the names of each element.
# So, for everything else to work, we need to rename "name" to be the name
# of the dimension.
if(length(trend_elements) == 1){
  names(trended_data) <- gsub("^name$", trend_elements, names(trended_data))
}

# If almost no orders have been placed, then it's not a probable bot
no_orders_data <- trended_data %>%
  filter(orders == 0)

# If no data is returned here, then go ahead and return NULL
if(nrow(no_orders_data) == 0){
  return(NULL)
}

# At this point, all we want is the visits data (plus the dimensions). Note the use
# of standard evaluation here (select_()) -- that's because we want to be able to try
# out different combinations of elements/dimensions, and that's needed to pass in 
# a vector of elements -- using .dots.

visits_data <- no_orders_data %>%
  select_("datetime", .dots = trend_elements, "visits")

# We're going to again use standard evaluation (note the group_by_() and .dots) to group by all
# of the elements specified earlier, plus the metric With that grouping, we then calculate the median absolute
# deviation (MAD) and then calculate a lower (min) and upper (max) bound for whether a 
# value is outside the expected range -- is an outlier.
find_min_max <- visits_data %>%
  group_by_(.dots = trend_elements) %>%
  summarise(min = median(visits) - mad(visits), max = median(visits) + mad(visits))

# Here's where we'll actually do the comparison of each value to the respective median PLUS 
# the MAD (we only care about spikes -- not dips) to ID which rows look to be a positive outlier. 
# There will be some super-low-volume combinations that pop up as outliers, so set a threshold for those.
find_deviations <- visits_data %>%
  left_join(find_min_max) %>%
  mutate(deviation = ifelse(visits > max, TRUE, FALSE)) %>%
  filter(deviation == TRUE & visits > 150) 

# Again... if we've eliminated everything, then go ahead and exit
if(nrow(find_deviations) == 0){
  return(NULL)
}

# We need one list that has just the unique combinations of the elements
deviation_combos <- find_deviations %>% 
  group_by_(.dots = trend_elements) %>%
  summarise()
    
# Join this back to the full data set so we have all of the data and can see the spike.
# First, join just to get all the data, then join again to get TRUE/FALSE on deviations.
# Then, mash together the dimensions into a single value
final_data <- deviation_combos %>%
  left_join(visits_data) %>% 
  left_join(find_deviations) %>% 
  mutate(deviation = ifelse(is.na(deviation), NA, visits)) %>% 
  unite_("combined_dims", trend_elements, sep = " > ")

# Do a little sorting -- ultimately, want to visualize from highest to lowest traffic
sort_order <- final_data %>% 
  group_by(combined_dims) %>% 
  summarise(total_visits = sum(visits)) %>% 
  arrange(-total_visits)

# Convert combined_dims to a factor so we get the order we want
final_data$combined_dims <- factor(final_data$combined_dims,
                                   levels = sort_order$combined_dims)

# Plot it!
final_plot <- ggplot(final_data, mapping = aes(x=datetime, y=visits)) +
  geom_bar(stat = "identity", fill = "gray80") +
  geom_bar(stat = "identity", mapping = aes(y=deviation), fill = "darkred") +
  geom_label(mapping = aes(x = median(unique(visits_data$datetime)), 
                          y = max(final_data$visits) * 1.1, label = combined_dims),
             label.r = unit(0, "lines"),
             label.size = 0) +
  facet_grid(combined_dims ~ .) +
  default_theme

}

```

## Possible Bots

```{r output, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}

final_plots <- lapply(elements_list, look_for_bots)

# Some of the checks won't return any results, so let's remove the NULL elements
final_plots <- final_plots[-which(sapply(final_plots, is.null))]

# And...output!
final_plots

```

